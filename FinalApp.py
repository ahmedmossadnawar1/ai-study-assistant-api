import streamlit as st
import os
import base64
import json
import re
from pptx import Presentation
from docx import Document as DocxDocument
from mistralai import Mistral
class RecursiveCharacterTextSplitter:
    def __init__(self, chunk_size=500, chunk_overlap=100, separators=None, length_function=len):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
    def split_text(self, text):
        chunks = []
        start = 0
        while start < len(text):
            end = start + self.chunk_size
            chunks.append(text[start:end])
            start += self.chunk_size - self.chunk_overlap
        return [c for c in chunks if c.strip()]
from typing import Optional, List, Dict, Tuple
import time
from io import BytesIO
from datetime import datetime
import hashlib


# PDF Libraries
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("âš ï¸ ReportLab not installed. PDF export will be disabled.")
    print("Install with: pip install reportlab")

# ======================================
# CONFIGURATION
# ======================================
st.set_page_config(
    layout="wide",
    page_title="AI Study Assistant",
    page_icon="ğŸ“",
    initial_sidebar_state="expanded"
)

# ======================================
# SIMPLE TRANSLATION HELPER
# ======================================
def T(ar: str, en: str) -> str:
    lang = st.session_state.get('ui_lang', 'ar')
    return ar if lang == 'ar' else en

# ======================================
# ADVANCED CACHING SYSTEM - VERY FAST
# ======================================
class FastCache:
    """Ù†Ø¸Ø§Ù… ÙƒØ§Ø´ Ù…ØªØ·ÙˆØ± Ù„Ù„ØºØ§ÙŠØ©"""
    
    @staticmethod
    @st.cache_resource
    def get_mistral_client(api_key: str):
        """Cache Mistral client forever"""
        try:
            return Mistral(api_key=api_key)
        except Exception as e:
            st.error(f"âŒ Failed to initialize Mistral client: {e}")
            return None
    
    @staticmethod
    @st.cache_data(ttl=3600, show_spinner=False)
    def get_file_hash(file_content: bytes) -> str:
        """Get file hash for caching"""
        return hashlib.md5(file_content).hexdigest()
    
    @staticmethod
    @st.cache_data(ttl=3600, show_spinner=False)
    def cache_extracted_text(file_hash: str, file_name: str, file_type: str, file_content: bytes) -> Tuple[str, dict]:
        """Cache extracted text based on file hash"""
        # This will be populated by the actual extraction function
        # We're just creating a placeholder for the cache key
        return "", {}
    
    @staticmethod
    @st.cache_data(ttl=7200, show_spinner=False)
    def cache_generated_features(text_hash: str, text_length: int) -> Dict:
        """Cache generated features - VERY IMPORTANT for speed"""
        # This is just a cache key placeholder
        return {}

# Initialize cache
cache = FastCache()

def get_text_hash(text: str) -> str:
    """Generate a hash for the text to use as cache key."""
    return hashlib.md5(text.encode('utf-8')).hexdigest()

# ======================================
# CHATBOT FUNCTIONS (Ø£Ø³Ù…Ø§Ø¡)
# ======================================
def initialize_chat_session(filename: str, extracted_text: str):
    """Initialize a new chat session for a specific file."""
    if 'chat_sessions' not in st.session_state:
        st.session_state['chat_sessions'] = {}

    if filename not in st.session_state['chat_sessions']:
        st.session_state['chat_sessions'][filename] = {
            'messages': [],
            'context': extracted_text[:10000],
            'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_tokens_used': 0
        }

    return st.session_state['chat_sessions'][filename]


def get_chat_context(filename: str) -> str:
    """Get the context text for the chat session."""
    if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
        return st.session_state['chat_sessions'][filename]['context']
    return ""


def add_chat_message(filename: str, role: str, content: str, tokens: int = 0):
    """Add a message to the chat history."""
    if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
        st.session_state['chat_sessions'][filename]['messages'].append({
            'role': role,
            'content': content,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })
        st.session_state['chat_sessions'][filename]['total_tokens_used'] += tokens

        if len(st.session_state['chat_sessions'][filename]['messages']) > 20:
            st.session_state['chat_sessions'][filename]['messages'] = \
                st.session_state['chat_sessions'][filename]['messages'][-20:]


def get_chat_messages(filename: str) -> List[Dict]:
    """Get chat messages for a specific file."""
    if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
        return st.session_state['chat_sessions'][filename]['messages']
    return []


def clear_chat_session(filename: str):
    """Clear chat history for a specific file."""
    if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
        st.session_state['chat_sessions'][filename]['messages'] = []
        st.session_state['chat_sessions'][filename]['total_tokens_used'] = 0
        st.session_state[f'chat_reset_{filename}'] = True


def format_error_message(error: Exception, context: str = "") -> str:
    """Format error messages based on error type."""
    error_str = str(error).lower()
    if "rate limit" in error_str or "429" in error_str:
        return "â³ API rate limit reached. Please wait a moment and try again."
    elif "authentication" in error_str or "401" in error_str or "api key" in error_str:
        return "ğŸ”‘ Invalid or expired API key. Please check your Mistral API key."
    elif "timeout" in error_str:
        return "â±ï¸ Request timeout. The file might be too complex or the server is busy."
    elif "connection" in error_str:
        return "ğŸŒ Connection error. Please check your internet connection."
    else:
        return f"âŒ {context}: {str(error)}"


def generate_chat_response(client, filename: str, user_message: str) -> str:
    """Generate AI response for chat based on document context."""
    try:
        chat_session = st.session_state['chat_sessions'][filename]
        context_text = chat_session['context']

        conversation_history = []
        for msg in chat_session['messages'][-10:]:
            conversation_history.append(f"{msg['role'].upper()}: {msg['content']}")

        history_text = "\n".join(conversation_history[-5:]) if conversation_history else "No previous conversation."

        system_prompt = f"""You are an AI Study Assistant specialized in explaining and discussing the uploaded document.

DOCUMENT CONTEXT:
{context_text[:8000]}

IMPORTANT INSTRUCTIONS:
1. You MUST answer based ONLY on the document content provided above
2. If the question is outside the document scope, politely say you can only answer based on the uploaded document
3. Support both English and Arabic languages seamlessly
4. Be helpful, educational, and precise
5. For Arabic questions, answer in Arabic. For English questions, answer in English
6. You can:
   - Explain concepts from the document
   - Answer specific questions about the content
   - Provide examples related to the material
   - Help with study strategies for this document
   - Clarify confusing parts
7. Keep answers concise but informative

PREVIOUS CONVERSATION:
{history_text}

USER'S QUESTION:
{user_message}

ANSWER:"""

        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7,
            max_tokens=1500
        )

        response_text = response.choices[0].message.content
        tokens_used = response.usage.total_tokens if hasattr(response, 'usage') else 0

        add_chat_message(filename, "user", user_message, tokens=0)
        add_chat_message(filename, "assistant", response_text, tokens=tokens_used)

        return response_text

    except Exception as e:
        error_msg = format_error_message(e, "Chat generation")
        return f"âŒ Error: {error_msg}"


def export_chat_history(filename: str):
    """Export chat history to a PDF file."""
    if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
        chat_session = st.session_state['chat_sessions'][filename]
        messages = chat_session['messages']

        pdf_content = f"Chat History for: {filename}\n"
        pdf_content += f"Created: {chat_session['created_at']}\n"
        pdf_content += f"Total Tokens Used: {chat_session['total_tokens_used']}\n"
        pdf_content += "="*50 + "\n\n"

        for msg in messages:
            pdf_content += f"{msg['role'].upper()} ({msg.get('timestamp', '')}):\n"
            pdf_content += f"{msg['content']}\n"
            pdf_content += "-"*40 + "\n"

        if PDF_AVAILABLE:
            try:
                pdf_buffer = create_pdf_from_text(pdf_content, f"Chat History - {filename}")
                st.download_button(
                    label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (PDF)", "ğŸ“¥ Download Chat History (PDF)"),
                    data=pdf_buffer,
                    file_name=f"{filename}_chat_history.pdf",
                    mime="application/pdf",
                    key=f"export_chat_{filename}"
                )
            except Exception as e:
                st.error(f"âŒ Error creating PDF: {str(e)[:100]}")
                st.download_button(
                    label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (TXT)", "ğŸ“¥ Download Chat History (TXT)"),
                    data=pdf_content,
                    file_name=f"{filename}_chat_history.txt",
                    mime="text/plain",
                    key=f"export_chat_txt_{filename}"
                )
        else:
            st.download_button(
                label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (TXT)", "ğŸ“¥ Download Chat History (TXT)"),
                data=pdf_content,
                file_name=f"{filename}_chat_history.txt",
                mime="text/plain",
                key=f"export_chat_txt_{filename}"
            )


def display_chat_interface(client, filename: str):
    """Display the chat interface for a specific document."""
    st.subheader(T("ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯", "ğŸ’¬ Document Chat Assistant"))
    st.markdown(T("**Ø§ØªÙƒÙ„Ù… Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨ØªØ§Ø¹Ùƒ:** ", "**Chat with your document:** ") + filename)
    st.markdown(T(
        "*ØªÙ‚Ø¯Ø± ØªØ³Ø£Ù„ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ*",
        "*You can ask questions in English or Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©*"
    ))
    st.markdown("---")

    if 'extracted_text' in st.session_state:
        initialize_chat_session(filename, st.session_state['extracted_text'])

    chat_container = st.container()
    with chat_container:
        messages = get_chat_messages(filename)
        if not messages:
            st.info(T(
                "ğŸ’¡ Ø§Ø¨Ø¯Ø£ ÙˆØ§Ø³Ø£Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ.",
                "ğŸ’¡ Start chatting! Ask questions about your document in English or Arabic."
            ))
            st.info(T(
                "ğŸ“š Ø£Ù…Ø«Ù„Ø©: 'Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©', 'Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©ØŸ', 'Ø§Ø¯ÙŠÙ†ÙŠ Ø£Ù…Ø«Ù„Ø©', 'Explain the main concepts'",
                "ğŸ“š Examples: 'Explain the main concepts', 'Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŸ', 'Give me examples', 'Ø§Ø´Ø±Ø­ Ù„ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡'"
            ))
        else:
            for msg in messages:
                if msg['role'] == 'user':
                    with st.chat_message("user", avatar="ğŸ‘¤"):
                        st.markdown(msg['content'])
                        st.caption(f"â° {msg.get('timestamp', '')}")
                else:
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.markdown(msg['content'])
                        st.caption(f"â° {msg.get('timestamp', '')}")

        st.markdown("---")

        chat_input_key = f"chat_input_{hash(filename) % 10000}"
        
        # Use chat_input instead of form for better performance
        user_input = st.chat_input(
            T("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...", "Type your message..."),
            key=chat_input_key
        )

        if user_input:
            if 'extracted_text' not in st.session_state:
                st.error(T(
                    "âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø³ØªÙ†Ø¯ Ù…Ø­Ù…Ù„. Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø±ÙØ¹ Ù…Ø³ØªÙ†Ø¯ Ø£ÙˆÙ„Ø§Ù‹.",
                    "âŒ No document loaded. Please upload a document first."
                ))
                st.stop()

            with st.spinner(T("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...", "ğŸ¤– Thinking...")):
                _ = generate_chat_response(client, filename, user_input)
            st.rerun()

    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        if st.button(T("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", "ğŸ—‘ï¸ Clear Chat"), key=f"clear_{filename}", use_container_width=True):
            clear_chat_session(filename)
            st.rerun()

    with col2:
        if st.button(T("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", "ğŸ’¾ Export Chat"), key=f"export_{filename}", use_container_width=True):
            export_chat_history(filename)

    with col3:
        if 'chat_sessions' in st.session_state and filename in st.session_state['chat_sessions']:
            token_count = st.session_state['chat_sessions'][filename]['total_tokens_used']
            st.caption(T(
                f"Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {token_count:,}",
                f"Tokens used: {token_count:,}"
            ))

    st.markdown(T("### âš¡ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø³Ø±ÙŠØ¹Ø©", "### âš¡ Quick Actions"))
    quick_cols = st.columns(4)
    quick_actions = {
        T("ğŸ“‹ ØªÙ„Ø®ÙŠØµ", "ğŸ“‹ Summarize"): "Please summarize the main points of this document in a clear and concise way.",
        T("â“ Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø©", "â“ Ask Questions"): "Generate 5 important questions based on this document with their answers.",
        T("ğŸ” Ø´Ø±Ø­", "ğŸ” Explain"): "Explain the most complex concept in this document in simple terms.",
        T("ğŸŒ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "ğŸŒ Translate"): "Translate the key points of this document to Arabic."
    }

    for idx, (btn_text, action_text) in enumerate(quick_actions.items()):
        with quick_cols[idx]:
            if st.button(btn_text, key=f"quick_{idx}_{filename}", use_container_width=True):
                if 'extracted_text' in st.session_state:
                    with st.spinner(T("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¬Ù‡ÙŠØ²...", "ğŸ¤– Thinking...")):
                        _ = generate_chat_response(client, filename, action_text)
                    st.rerun()

# ======================================
# FILE VALIDATION
# ======================================
def validate_file(file, max_size_mb: float = 50) -> Tuple[bool, str]:
    """Validate file before processing."""
    try:
        if not file or file.size == 0:
            return False, "âŒ Empty file detected"
        size_mb = file.size / (1024 * 1024)
        if size_mb > max_size_mb:
            return False, f"âŒ File too large: {size_mb:.1f}MB (Max: {max_size_mb}MB)"
        return True, f"âœ… Valid file ({size_mb:.2f}MB)"
    except Exception as e:
        return False, f"âŒ Validation error: {str(e)}"

# ======================================
# TEXT CLEANING & PREPROCESSING
# ======================================
def clean_text(text: str) -> str:
    """Clean the extracted text - Basic cleaning."""
    if not text:
        return ""
    text = text.replace("\t", " ")
    text = text.replace("\xa0", " ")
    text = " ".join(text.split())
    return text.strip()


def chunk_text(text: str, chunk_size: int = 500, chunk_overlap: int = 100) -> List[str]:
    """Split text into overlapping chunks."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ". ", " ", ""],
        length_function=len,
    )
    chunks = splitter.split_text(text)
    return chunks

# ======================================
# HELPERS
# ======================================
def get_file_extension(filename: str) -> str:
    """Get file extension safely."""
    return os.path.splitext(filename)[1].lower()

# ======================================
# EXTRACTION FUNCTIONS (ÙŠÙˆØ³Ù)
# ======================================
def extract_from_word(docx_file) -> Tuple[str, dict]:
    """Extract text from Word document."""
    try:
        doc = DocxDocument(docx_file)
        all_text = []
        metadata = {
            "paragraphs": len(doc.paragraphs),
            "tables": len(doc.tables),
            "sections": len(doc.sections),
            "errors": []
        }

        for para in doc.paragraphs:
            if para.text.strip():
                all_text.append(para.text)

        for table in doc.tables:
            all_text.append("\n[Table Start]")
            for row in table.rows:
                row_text = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                if row_text:
                    all_text.append(" | ".join(row_text))
            all_text.append("[Table End]\n")

        final_text = "\n\n".join(all_text)
        return clean_text(final_text), metadata

    except Exception as e:
        error_msg = format_error_message(e, "Word extraction")
        return error_msg, {"error": str(e)}

def extract_from_txt(txt_file) -> Tuple[str, dict]:
    """Extract text from TXT file with multiple encoding support."""
    encodings = ['utf-8', 'utf-8-sig', 'cp1256', 'latin-1', 'iso-8859-1']
    for encoding in encodings:
        try:
            txt_file.seek(0)
            content = txt_file.read().decode(encoding)
            lines = content.split('\n')
            metadata = {
                "lines": len(lines),
                "characters": len(content),
                "words": len(content.split()),
                "encoding": encoding
            }
            return clean_text(content), metadata
        except (UnicodeDecodeError, AttributeError):
            continue

    return "Error: Could not decode text file with supported encodings", {
        "error": "Encoding not supported",
        "tried_encodings": encodings
    }

def pptx_extract_text(pptx_file, client) -> Tuple[str, dict]:
    """Extract text + tables + OCR from images inside PPTX."""
    try:
        prs = Presentation(pptx_file)
        all_slides_output = []
        metadata = {
            "total_slides": len(prs.slides),
            "slides_with_images": 0,
            "slides_with_tables": 0,
            "total_images_ocr": 0,
            "successful_ocr": 0,
            "failed_ocr": 0,
            "total_tables": 0,
            "errors": []
        }

        for slide_number, slide in enumerate(prs.slides, start=1):
            slide_text_parts = [f"=== Slide {slide_number} ==="]
            has_images = False
            has_tables = False

            for shape in slide.shapes:
                try:
                    if hasattr(shape, "text_frame") and shape.text_frame:
                        text = shape.text_frame.text.strip()
                        if text:
                            slide_text_parts.append(text)
                    elif hasattr(shape, "text") and isinstance(shape.text, str):
                        text = shape.text.strip()
                        if text:
                            slide_text_parts.append(text)
                except Exception as e:
                    metadata["errors"].append(f"Slide {slide_number}: Text extraction error - {str(e)}")

            for shape in slide.shapes:
                try:
                    if shape.has_table:
                        has_tables = True
                        metadata["total_tables"] += 1
                        table = shape.table
                        slide_text_parts.append("\n[Table Start]")
                        for row in table.rows:
                            row_data = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                            if row_data:
                                slide_text_parts.append(" | ".join(row_data))
                        slide_text_parts.append("[Table End]\n")
                except Exception as e:
                    metadata["errors"].append(f"Slide {slide_number}: Table extraction error - {str(e)}")

            for shape_idx, shape in enumerate(slide.shapes):
                if hasattr(shape, "image"):
                    has_images = True
                    metadata["total_images_ocr"] += 1
                    try:
                        image = shape.image
                        image_bytes = image.blob
                        mime = image.ext if image.ext in ["png", "jpg", "jpeg"] else "png"

                        image_size_mb = len(image_bytes) / (1024 * 1024)
                        if image_size_mb > 10:
                            metadata["errors"].append(
                                f"Slide {slide_number}, Image {shape_idx}: Image too large ({image_size_mb:.1f}MB)"
                            )
                            metadata["failed_ocr"] += 1
                            continue

                        encoded = base64.b64encode(image_bytes).decode("utf-8")
                        document = {
                            "type": "image_url",
                            "image_url": f"data:image/{mime};base64,{encoded}"
                        }

                        response = client.ocr.process(
                            model="mistral-ocr-latest",
                            document=document,
                            include_image_base64=False
                        )

                        if not hasattr(response, 'pages') or not response.pages:
                            metadata["failed_ocr"] += 1
                            continue

                        ocr_text_found = False
                        for page in response.pages:
                            page_text = None
                            if hasattr(page, 'markdown') and page.markdown:
                                page_text = page.markdown.strip()
                            elif hasattr(page, 'text') and page.text:
                                page_text = page.text.strip()

                            if page_text:
                                slide_text_parts.append(
                                    f"\n[Image OCR - Shape {shape_idx}]\n{page_text}"
                                )
                                ocr_text_found = True
                                metadata["successful_ocr"] += 1

                        if not ocr_text_found:
                            metadata["failed_ocr"] += 1
                    except Exception as e:
                        metadata["errors"].append(
                            f"Slide {slide_number}, Image {shape_idx}: {str(e)}"
                        )
                        metadata["failed_ocr"] += 1

            if has_images:
                metadata["slides_with_images"] += 1
            if has_tables:
                metadata["slides_with_tables"] += 1

            slide_output = "\n".join(slide_text_parts)
            all_slides_output.append(slide_output)

        final_text = "\n\n--- Slide Break ---\n\n".join(all_slides_output)
        return final_text.strip(), metadata

    except Exception as e:
        error_msg = format_error_message(e, "PPTX processing")
        return error_msg, {"error": str(e)}

def ocr_mistral(file, filename: str, client) -> Tuple[str, dict]:
    """OCR for images/PDF using Mistral."""
    metadata = {
        "filename": filename,
        "file_type": file.type,
        "pages_processed": 0,
        "errors": []
    }
    try:
        file_bytes = file.read()
        file.seek(0)
        file_size_mb = len(file_bytes) / (1024 * 1024)
        metadata["file_size_mb"] = round(file_size_mb, 2)

        if file_size_mb > 50:
            error_msg = f"âŒ File exceeds Mistral OCR limit of 50MB (Current size: {file_size_mb:.1f}MB)"
            metadata["errors"].append(error_msg)
            return error_msg, metadata

        if len(file_bytes) == 0:
            return "Error: Empty file", metadata

        encoded = base64.b64encode(file_bytes).decode("utf-8")
        mime = file.type
        ext = get_file_extension(filename)

        if ext == ".pdf":
            document = {
                "type": "document_url",
                "document_url": f"data:application/pdf;base64,{encoded}"
            }
        else:
            document = {
                "type": "image_url",
                "image_url": f"data:{mime};base64:{encoded}"
            }

        response = client.ocr.process(
            model="mistral-ocr-latest",
            document=document,
            include_image_base64=False
        )

        final_text = ""
        pages = getattr(response, "pages", [])
        metadata["pages_processed"] = len(pages)

        for page in pages:
            page_text = getattr(page, "markdown", None) or getattr(page, "text", "")
            final_text += page_text + "\n\n"

        return final_text.strip(), metadata

    except Exception as e:
        error_msg = format_error_message(e, "OCR processing")
        metadata["errors"].append(error_msg)
        return error_msg, metadata

# ======================================
# PDF EXPORT FUNCTION - WITH ARABIC SUPPORT
# ======================================
def create_pdf_from_text(text: str, title: str) -> BytesIO:
    """Convert text to PDF with Arabic and English support"""
    if not PDF_AVAILABLE:
        raise Exception("ReportLab not installed. Install with: pip install reportlab")

    try:
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from bidi.algorithm import get_display
        import arabic_reshaper
        ARABIC_SUPPORT = True
    except ImportError:
        ARABIC_SUPPORT = False
        print("âš ï¸ Arabic support disabled. Install: pip install python-bidi arabic-reshaper")

    buffer = BytesIO()
    doc = SimpleDocTemplate(
        buffer,
        pagesize=A4,
        topMargin=0.5*inch,
        bottomMargin=0.5*inch
    )

    font_name = 'Helvetica'
    if ARABIC_SUPPORT:
        try:
            arabic_fonts = [
                'C:/Windows/Fonts/arial.ttf',
                'C:/Windows/Fonts/tahoma.ttf',
                'C:/Windows/Fonts/calibri.ttf',
                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
                '/System/Library/Fonts/Supplemental/Arial.ttf'
            ]
            for font_path in arabic_fonts:
                if os.path.exists(font_path):
                    pdfmetrics.registerFont(TTFont('Arabic', font_path))
                    font_name = 'Arabic'
                    break
        except Exception as e:
            print(f"âš ï¸ Could not load Arabic font: {e}")
            font_name = 'Helvetica'

    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=20,
        spaceAfter=30,
        alignment=TA_CENTER,
        fontName=font_name
    )
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=14,
        spaceAfter=12,
        spaceBefore=12,
        fontName=font_name
    )
    normal_style = ParagraphStyle(
        'CustomNormal',
        parent=styles['Normal'],
        fontSize=11,
        leading=16,
        spaceAfter=8,
        fontName=font_name,
        alignment=TA_JUSTIFY
    )

    def contains_arabic(t):
        return any('\u0600' <= c <= '\u06FF' for c in t)

    def process_text(t):
        if ARABIC_SUPPORT and contains_arabic(t):
            try:
                reshaped = arabic_reshaper.reshape(t)
                return get_display(reshaped)
            except Exception:
                return t
        return t

    story = []

    try:
        processed_title = process_text(title)
        story.append(Paragraph(processed_title, title_style))
    except Exception:
        story.append(Paragraph(title, title_style))

    story.append(Spacer(1, 0.3*inch))

    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            story.append(Spacer(1, 0.05*inch))
            continue

        line = line.replace('â•', '-').replace('â”‚', '|').replace('â””', '+')
        line = line.replace('â”œ', '+').replace('â”Œ', '+').replace('â”€', '-')

        is_heading = (
            line.startswith('##') or
            line.startswith('###') or
            line.startswith('ğŸ¯') or
            line.startswith('ğŸ“Œ') or
            (line.startswith('**') and line.endswith('**'))
        )

        line = line.replace('#', '').replace('**', '').strip()
        if not line:
            continue

        processed_line = process_text(line)

        try:
            if is_heading:
                story.append(Paragraph(processed_line, heading_style))
            elif line.startswith('-') or line.startswith('â€¢') or line.startswith('+'):
                clean_line = line.lstrip('-â€¢+').strip()
                processed_clean = process_text(clean_line)
                story.append(Paragraph(f"â€¢ {processed_clean}", normal_style))
            else:
                story.append(Paragraph(processed_line, normal_style))
        except Exception:
            try:
                story.append(Paragraph(line, normal_style))
            except Exception:
                continue

    try:
        doc.build(story)
    except Exception as e:
        print(f"âš ï¸ PDF build error: {e}")

    buffer.seek(0)
    return buffer

def create_download_button_pdf(content: str, base_filename: str, title: str, key_prefix: str):
    """Create download button for PDF format only"""
    if PDF_AVAILABLE:
        try:
            pdf_buffer = create_pdf_from_text(content, title)
            st.download_button(
                label=T("ğŸ“• ØªØ­Ù…ÙŠÙ„ PDF", "ğŸ“• Download PDF"),
                data=pdf_buffer,
                file_name=f"{base_filename}.pdf",
                mime="application/pdf",
                key=f"{key_prefix}_pdf",
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"âš ï¸ PDF Error: {str(e)[:50]}")
            st.button("ğŸ“• PDF (Error)", disabled=True, use_container_width=True)
    else:
        with st.expander("ğŸ“• PDF Not Available"):
            st.code("pip install reportlab")
            st.info("Install ReportLab to enable PDF export")

# ======================================
# TRANSLATION HELPER (for UI switching)
# ======================================
def translate_text(client, text: str, target_lang: str) -> str:
    """
    Translate given text to target_lang ('ar' or 'en').
    Uses caching in session_state to avoid repeated API calls.
    """
    if not text:
        return ""

    cache_key = f"translation_{target_lang}_" + str(hash(text))
    if cache_key in st.session_state:
        return st.session_state[cache_key]

    try:
        if target_lang == "ar":
            prompt = f"Translate the following text to clear Arabic suitable for students:\n\n{text}"
        else:
            prompt = f"Translate the following text to clear English suitable for students:\n\n{text}"

        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=2000
        )
        translated = response.choices[0].message.content
        st.session_state[cache_key] = translated
        return translated
    except Exception as e:
        return f"âŒ Translation error: {str(e)}"


# ======================================
# AI FEATURES (Ø£Ø­Ù…Ø¯) - AR + EN
# ======================================

def generate_summary(client, text: str, lang: str) -> str:
    """Generate summary in given lang ('en' or 'ar')."""
    try:
        if lang == 'ar':
            instructions = """
Ø§ÙƒØªØ¨ Ù…Ù„Ø®ØµÙ‹Ø§ Ù…Ù†Ø¸Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
- Ù‚Ø³Ù… Ø§Ù„Ù…Ù„Ø®Øµ Ø¥Ù„Ù‰ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø±Ø¦ÙŠØ³ÙŠØ© ÙØ±Ø¹ÙŠØ©.
- ØªØ­Øª ÙƒÙ„ Ø¹Ù†ÙˆØ§Ù†ØŒ Ø§ÙƒØªØ¨ Ù†Ù‚Ø§Ø· Ù…Ø®ØªØµØ±Ø© ÙˆÙˆØ§Ø¶Ø­Ø©.
- Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø±ÙŠÙØ§ØªØŒ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†ØŒ ÙˆØ§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ù„Ø®Øµ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†.
"""
        else:
            instructions = """
Write a well-structured summary in English:
- Divide the summary into clear sections with headings.
- Under each heading, use concise bullet points.
- Focus on definitions, key concepts, and main ideas.
- Make it suitable for quick exam revision.
"""

        prompt = f"""
You are an expert in summarizing academic content.
{instructions}

Text:
{text[:15000]}

Structured Summary:
"""
        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Error generating summary ({lang}): {str(e)}"


def generate_quiz(client, text: str, num_questions: int, lang: str) -> dict:
    """Generate quiz in given lang ('en' or 'ar')."""
    try:
        if lang == 'ar':
            lang_rules = """
- Ø§ÙƒØªØ¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª ÙˆØ§Ù„ØªÙˆØ¶ÙŠØ­Ø§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
- Ø§Ø¬Ø¹Ù„ ØµÙŠØ§ØºØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ø·Ù„Ø§Ø¨.
"""
        else:
            lang_rules = """
- Write all questions, options, and explanations in clear English.
"""

        prompt = f"""
Create a quiz in PURE JSON format. No markdown, no explanation, ONLY JSON.
Return exactly this structure:
{{
  "questions": [
    {{
      "question": "What is the capital of France?",
      "options": ["London", "Paris", "Berlin", "Madrid"],
      "correct_answer": 1,
      "explanation": "Paris is the capital and largest city of France."
    }}
  ]
}}

Rules:
- {num_questions} questions total
- Each question has exactly 4 options
- correct_answer is the index (0, 1, 2, or 3)
- Cover different key topics from the text
{lang_rules}
- Return ONLY valid JSON (no extra text)

Text to create quiz from:
{text[:15000]}

JSON Quiz:
"""
        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=3000
        )

        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()

        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            content = json_match.group(0)

        quiz_data = json.loads(content)

        if 'questions' not in quiz_data or not isinstance(quiz_data['questions'], list):
            return {"questions": []}

        valid_questions = []
        for q in quiz_data['questions']:
            if (
                isinstance(q, dict)
                and 'question' in q
                and 'options' in q
                and 'correct_answer' in q
                and isinstance(q['options'], list)
                and len(q['options']) == 4
                and isinstance(q['correct_answer'], int)
                and 0 <= q['correct_answer'] < 4
            ):
                valid_questions.append(q)

        return {"questions": valid_questions}
    except Exception as e:
        return {"questions": [], "error": f"âŒ Quiz error ({lang}): {str(e)}"}


def generate_mindmap(client, text: str, lang: str) -> str:
    """Generate mind map in given lang ('en' or 'ar')."""
    try:
        if lang == 'ar':
            instructions = """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±Ø§Ø¦Ø· Ø°Ù‡Ù†ÙŠØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ©.
Ø£Ù†Ø´Ø¦ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ù…Ù†Ø¸Ù…Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ.

Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:
- Ø§Ø¬Ø¹Ù„ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©.
- Ø£Ù†Ø´Ø¦ Ù…Ù† 4 Ø¥Ù„Ù‰ 6 ÙØ±ÙˆØ¹ Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙ‚Ø·.
- ÙƒÙ„ ÙØ±Ø¹ Ø±Ø¦ÙŠØ³ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 2 Ø¥Ù„Ù‰ 5 Ù†Ù‚Ø§Ø· ÙØ±Ø¹ÙŠØ©.
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ Ø¨Ø³ÙŠØ· Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø´ÙƒÙ„ Ø¬Ø°Ø§Ø¨Ù‹Ø§.
- Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚Ù‹Ø§ Ù‡Ø±Ù…ÙŠÙ‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§ (Ø¹Ù†Ø§ÙˆÙŠÙ† Ø±Ø¦ÙŠØ³ÙŠØ© Ø«Ù… Ù†Ù‚Ø§Ø· ÙØ±Ø¹ÙŠØ©).
- Ø§ÙƒØªØ¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
"""
        else:
            instructions = """
You are an expert in creating stunning educational mind maps.
Create a beautifully organized mind map from the following text.

Requirements:
- Start with a clear, concise MAIN TOPIC.
- Create 4â€“6 MAIN BRANCHES only.
- Each main branch should have 2â€“5 sub-points.
- Use emojis sparingly for visual appeal.
- Use clear hierarchical formatting (main topic â†’ branches â†’ sub-points).
- Write everything in English.
"""

        prompt = f"""
{instructions}

Text:
{text[:15000]}

Mind Map:
"""
        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=2500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Error generating mind map ({lang}): {str(e)}"


def generate_question_bank(client, text: str, num_questions: int, lang: str) -> str:
    """Generate question bank in given lang ('en' or 'ar')."""
    try:
        if lang == 'ar':
            instructions = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨Ù†ÙˆÙƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù„Ù„Ø§Ù…ØªØ­Ø§Ù†Ø§Øª.

Ø£Ù†Ø´Ø¦ Ø¨Ù†Ùƒ Ø£Ø³Ø¦Ù„Ø© Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ.

Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {num_questions}
- Ø§Ù„ØªÙˆØ²ÙŠØ¹:
  - ØµØ­/Ø®Ø·Ø£ (~30%)
  - Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ (~40%)
  - Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚Ø§Ù„ÙŠØ©/Ù‚ØµÙŠØ±Ø© (~30%)
- Ø¶Ø¹ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§ Ù„ÙƒÙ„ Ù‚Ø³Ù…:
  - Ø£ÙˆÙ„Ù‹Ø§: Ø£Ø³Ø¦Ù„Ø© ØµØ­ ÙˆØ®Ø·Ø£
  - Ø«Ø§Ù†ÙŠÙ‹Ø§: Ø£Ø³Ø¦Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯
  - Ø«Ø§Ù„Ø«Ù‹Ø§: Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚Ø§Ù„ÙŠØ© Ù‚ØµÙŠØ±Ø©
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¶Ø­Ø©.
- Ø¥Ø¬Ø§Ø¨Ø§Øª Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ­ ÙˆØ§Ù„Ø®Ø·Ø£ Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† Ù…Ø«Ù„: (ØµØ­) Ø£Ùˆ (Ø®Ø·Ø£).
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆØ¨Ø³ÙŠØ·Ø©.
"""
        else:
            instructions = f"""
You are an expert exam creator.

Create a professional, well-formatted question bank from the text below.

Requirements:
- Total questions: {num_questions}
- Distribution:
  - True/False (~30%)
  - Multiple Choice (~40%)
  - Short Answer (~30%)
- Add clear section headings:
  - Section 1: True/False Questions
  - Section 2: Multiple Choice Questions
  - Section 3: Short Answer Questions
- Use clear spacing between questions.
- True/False answers MUST be in parentheses like (True) or (False).
- Provide brief explanations or notes after the answer when possible.
- Use clear, exam-style English.
"""

        prompt = f"""
{instructions}

Text:
{text[:15000]}

Question Bank:
"""
        response = client.chat.complete(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=4500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Error generating question bank ({lang}): {str(e)}"


def generate_all_features(client, text: str, filename: str):
    """
    Generate all 4 features automatically after file upload
    in BOTH English and Arabic, once.
    """
    # Use progress indicators
    progress_bar = st.progress(0)
    status_text = st.empty()

    features_en = {}
    features_ar = {}

    try:
        # ---------- ENGLISH ----------
        status_text.text("ğŸ¤– Generating English Summary...")
        progress_bar.progress(5)
        features_en['summary'] = generate_summary(client, text, 'en')

        status_text.text("ğŸ¤– Generating English Quiz...")
        progress_bar.progress(20)
        features_en['quiz'] = generate_quiz(client, text, num_questions=10, lang='en')

        status_text.text("ğŸ¤– Generating English Mind Map...")
        progress_bar.progress(35)
        features_en['mindmap'] = generate_mindmap(client, text, 'en')

        status_text.text("ğŸ¤– Generating English Question Bank...")
        progress_bar.progress(50)
        features_en['questionbank'] = generate_question_bank(client, text, num_questions=20, lang='en')

        # ---------- ARABIC ----------
        status_text.text("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
        progress_bar.progress(60)
        features_ar['summary'] = generate_summary(client, text, 'ar')

        status_text.text("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙˆÙŠØ² Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
        progress_bar.progress(75)
        features_ar['quiz'] = generate_quiz(client, text, num_questions=10, lang='ar')

        status_text.text("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
        progress_bar.progress(85)
        features_ar['mindmap'] = generate_mindmap(client, text, 'ar')

        status_text.text("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ù†Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
        progress_bar.progress(95)
        features_ar['questionbank'] = generate_question_bank(client, text, num_questions=20, lang='ar')

        progress_bar.progress(100)
        status_text.success("âœ… All Arabic & English features generated!")
        time.sleep(1)
        status_text.empty()
        progress_bar.empty()

        # Store in session state
        st.session_state['features_en'] = features_en
        st.session_state['features_ar'] = features_ar
        st.session_state['last_filename'] = filename
        st.session_state['text_hash'] = get_text_hash(text)
        st.session_state['features_generated'] = True

        return {"en": features_en, "ar": features_ar}
    except Exception as e:
        status_text.error(f"âŒ Error during generation: {str(e)}")
        return {"en": features_en, "ar": features_ar}

# ======================================
# RENDER HELPER FOR ARABIC HTML - Ø¨Ø¯ÙˆÙ† Ø®Ù„ÙÙŠØ© Ø¨Ù„ÙˆÙ† Ø£Ø¨ÙŠØ¶
# ======================================
def render_content(text: str):
    """Render AI text nicely in Arabic (RTL) or English (Markdown)."""
    lang = st.session_state.get('ui_lang', 'ar')
    
    if lang == 'ar':
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø£ÙŠ ØªÙ†Ø³ÙŠÙ‚Ø§Øª HTML Ø£Ùˆ Markdown
        import re
        
        # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ÙˆØ³ÙˆÙ… HTML Ù…ÙˆØ¬ÙˆØ¯Ø©
        text = re.sub(r'<[^>]+>', '', text)
        
        # Ø¥Ø²Ø§Ù„Ø© ØªÙ†Ø³ÙŠÙ‚Ø§Øª Markdown
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **Ù†Øµ**
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # *Ù†Øµ*
        text = re.sub(r'__(.*?)__', r'\1', text)      # __Ù†Øµ__
        text = re.sub(r'_(.*?)_', r'\1', text)        # _Ù†Øµ_
        text = re.sub(r'`(.*?)`', r'\1', text)        # `Ù†Øµ`
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø¨Ù„ÙˆÙ† Ø£Ø¨ÙŠØ¶ (Ø¨Ø¯ÙˆÙ† Ø®Ù„ÙÙŠØ©)
        st.markdown(f"""
        <div style="
            direction: rtl;
            text-align: right;
            padding: 10px;
            font-family: 'Segoe UI', 'Arial', sans-serif;
            font-size: 16px;
            line-height: 1.8;
            white-space: pre-wrap;
            word-wrap: break-word;
            color: #FFFFFF;
        ">
        {text}
        </div>
        """, unsafe_allow_html=True)
    else:
        # Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© - Ø¹Ø±Ø¶ Ø¹Ø§Ø¯ÙŠ
        st.markdown(text)


# ======================================
# INTERACTIVE QUIZ DISPLAY (RTL READY)
# ======================================
def display_interactive_quiz(quiz_data: dict, filename: str):
    """Display interactive quiz with immediate feedback (RTL friendly)."""
    lang = st.session_state.get('ui_lang', 'ar')
    is_ar = (lang == 'ar')

    if not quiz_data or 'questions' not in quiz_data or len(quiz_data['questions']) == 0:
        st.error(T("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ø¦Ù„Ø© ÙƒÙˆÙŠØ² Ù…ØªØ§Ø­Ø©", "âŒ No quiz questions available"))
        st.info(T(
            "ğŸ’¡ Ù…Ù…ÙƒÙ† Ø§Ù„Ù€ AI ÙˆØ§Ø¬Ù‡ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙˆÙŠØ². Ø¬Ø±Ù‘Ø¨ ØªØ±ÙØ¹ Ù…Ù„Ù ØªØ§Ù†ÙŠ Ø£Ùˆ ØªØ¹ÙŠØ¯ Ø§Ù„Ø±ÙØ¹.",
            "ğŸ’¡ The AI might have had trouble generating the quiz. Try uploading the file again or use a different document."
        ))
        return

    if is_ar:
        st.markdown("""
            <style>
            div.stRadio > div {
                direction: rtl;
                text-align: right;
            }
            div.stRadio label {
                direction: rtl;
                text-align: right;
            }
            </style>
        """, unsafe_allow_html=True)

    st.subheader(T("â“ ÙƒÙˆÙŠØ² ØªÙØ§Ø¹Ù„ÙŠ", "â“ Interactive Quiz"))
    st.markdown(T(
        f"**Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {len(quiz_data['questions'])} - Ø¬Ø§ÙˆØ¨ ÙˆØ®Ø¯ ÙÙŠØ¯Ø¨Ø§Ùƒ ÙÙˆØ±Ù‹Ø§!**",
        f"**{len(quiz_data['questions'])} Questions - Answer each question and get instant feedback!**"
    ))
    st.markdown("---")

    if 'quiz_answers' not in st.session_state:
        st.session_state['quiz_answers'] = {}
    if 'quiz_submitted' not in st.session_state:
        st.session_state['quiz_submitted'] = {}

    total_questions = len(quiz_data['questions'])
    correct_count = 0

    for idx, q in enumerate(quiz_data['questions']):
        question_key = f"q_{idx}"

        st.markdown(T(
            f"### Ø§Ù„Ø³Ø¤Ø§Ù„ {idx + 1} Ù…Ù† {total_questions}",
            f"### Question {idx + 1} of {total_questions}"
        ))
        st.markdown(f"**{q['question']}**")

        user_answer = st.radio(
            T("Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:", "Select your answer:"),
            options=range(len(q['options'])),
            format_func=lambda x: f"{chr(65+x)}) {q['options'][x]}",
            key=f"radio_{filename}_{question_key}",
            index=None,
            horizontal=False
        )

        col1, col2 = st.columns([1, 4])
        with col1:
            submit_btn = st.button(
                T("ØªØ£ÙƒÙŠØ¯", "Submit"),
                key=f"submit_{filename}_{question_key}"
            )

        if submit_btn and user_answer is not None:
            st.session_state['quiz_answers'][question_key] = user_answer
            st.session_state['quiz_submitted'][question_key] = True

        if st.session_state['quiz_submitted'].get(question_key, False):
            user_ans = st.session_state['quiz_answers'][question_key]
            correct_ans = q['correct_answer']

            if user_ans == correct_ans:
                st.success(T("âœ… Ø¥Ø¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø©", "âœ… Correct!"))
                correct_count += 1
            else:
                st.error(T(
                    f"âŒ Ø¥Ø¬Ø§Ø¨Ø© Ø®Ø§Ø·Ø¦Ø©. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: {chr(65+correct_ans)}) {q['options'][correct_ans]}",
                    f"âŒ Wrong! The correct answer is: {chr(65+correct_ans)}) {q['options'][correct_ans]}"
                ))

            if 'explanation' in q and q['explanation']:
                st.info(T(
                    f"ğŸ’¡ Ø§Ù„ØªÙˆØ¶ÙŠØ­: {q['explanation']}",
                    f"ğŸ’¡ Explanation: {q['explanation']}"
                ))

        st.markdown("---")

    submitted_count = sum(1 for k in st.session_state['quiz_submitted'].values() if k)
    if submitted_count == total_questions:
        score_percentage = (correct_count / total_questions) * 100
        st.markdown(T("### ğŸ“Š Ù†ØªÙŠØ¬ØªÙƒ", "### ğŸ“Š Your Score"))
        st.metric(
            T("Ø§Ù„Ù†ØªÙŠØ¬Ø©", "Score"),
            f"{correct_count}/{total_questions} ({score_percentage:.1f}%)"
        )

        if score_percentage >= 80:
            st.balloons()
            st.success(T("ğŸ‰ Ù…Ù…ØªØ§Ø²! Ø´ØºÙ„ Ø¹Ø§Ù„ÙŠ!", "ğŸ‰ Excellent work!"))
        elif score_percentage >= 60:
            st.info(T("ğŸ‘ Ø¬ÙŠØ¯! Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©.", "ğŸ‘ Good job! Keep practicing!"))
        else:
            st.warning(T("ğŸ“š Ù…Ø­ØªØ§Ø¬ ØªØ±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØªØ¹ÙŠØ¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.", "ğŸ“š Review the material and try again!"))

        if st.button(T("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ÙƒÙˆÙŠØ²", "ğŸ”„ Reset Quiz")):
            st.session_state['quiz_answers'] = {}
            st.session_state['quiz_submitted'] = {}
            st.rerun()


# ======================================
# STREAMLIT UI - MAIN
# ======================================
def main():
    if 'ui_lang' not in st.session_state:
        st.session_state['ui_lang'] = 'ar'
    
    # Initialize session state variables if they don't exist
    if 'features_en' not in st.session_state:
        st.session_state['features_en'] = {}
    if 'features_ar' not in st.session_state:
        st.session_state['features_ar'] = {}
    if 'last_filename' not in st.session_state:
        st.session_state['last_filename'] = None
    if 'last_file_hash' not in st.session_state:
        st.session_state['last_file_hash'] = None
    if 'text_hash' not in st.session_state:
        st.session_state['text_hash'] = None
    if 'selected_feature' not in st.session_state:
        st.session_state['selected_feature'] = 'summarize'
    if 'features_generated' not in st.session_state:
        st.session_state['features_generated'] = False
    if 'processed_files' not in st.session_state:
        st.session_state['processed_files'] = {}  # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§

    with st.sidebar:
        st.header("âš™ï¸ Settings")
        lang = st.radio(
            "Language / Ø§Ù„Ù„ØºØ©",
            options=['ar', 'en'],
            format_func=lambda x: "ğŸ‡ªğŸ‡¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if x == 'ar' else "ğŸ‡¬ğŸ‡§ English",
            key="ui_lang_radio"
        )
        st.session_state['ui_lang'] = lang

        api_key = st.text_input(
            T("ğŸ”‘ Ù…ÙØªØ§Ø­ Mistral API", "ğŸ”‘ Mistral API Key"),
            type="password",
            help=T("Ø§ÙƒØªØ¨ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Mistral", "Enter your Mistral API key")
        )

        if not api_key:
            st.warning(T(
                "âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API Ù„Ù„Ø¨Ø¯Ø¡",
                "âš ï¸ Please enter your API Key to start"
            ))
            st.info("Get your free API key from: https://console.mistral.ai/")
            st.stop()

        client = cache.get_mistral_client(api_key)
        if not client:
            st.error(T(
                "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Mistral API",
                "âŒ Failed to connect to Mistral API"
            ))
            st.stop()
        st.success(T("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­!", "âœ… Connected successfully!"))
        st.markdown("---")

        st.subheader(T("ğŸ“ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", "ğŸ“ Processing Settings"))
        chunk_size = st.slider(
            T("Ø­Ø¬Ù… Ø§Ù„Ø¬Ø²Ø¡ (Chunk Size)", "Chunk Size"),
            min_value=300,
            max_value=1000,
            value=500,
            step=50,
            help=T(
                "Ø­Ø¬Ù… ÙƒÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ Ø¹Ù†Ø¯ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…",
                "Size of each text chunk"
            )
        )
        chunk_overlap = st.slider(
            T("ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ (Overlap)", "Chunk Overlap"),
            min_value=50,
            max_value=300,
            value=100,
            step=25,
            help=T(
                "Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„ØªØ¯Ø§Ø®Ù„ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡",
                "Overlap between chunks"
            )
        )

        st.markdown("---")
        st.info(T(
            "ğŸ’¡ **ÙƒÙ„ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ù‡ØªØªÙˆÙ„Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù!**",
            "ğŸ’¡ **All features are generated automatically after file upload!**"
        ))

        if not PDF_AVAILABLE:
            st.warning("âš ï¸ PDF export disabled. Install: `pip install reportlab`")
        else:
            st.success("âœ… PDF export enabled")

    lang = st.session_state.get('ui_lang', 'ar')
    direction = "rtl" if lang == 'ar' else "ltr"
    align = "right" if lang == 'ar' else "left"

    st.markdown(f"""
        <style>
        .main, .block-container {{
            direction: {direction};
            text-align: {align};
        }}
        div[role="textbox"], textarea, input, label, p, span, h1, h2, h3, h4, h5 {{
            direction: {direction};
            text-align: {align};
        }}
        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ù„ØªÙƒÙˆÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø­Ø¬Ù… */
        div.stButton > button {{
            width: 100%;
            height: 50px;
            font-size: 16px;
            font-weight: bold;
        }}
        </style>
    """, unsafe_allow_html=True)

    st.title(T("ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "ğŸ“ AI Study Assistant"))
    st.markdown(T(
        "**Ø§Ø±ÙØ¹ Ù…Ù„ÙÙƒ ÙˆØ®Ø¯ Ù…Ù„Ø®ØµØŒ ÙƒÙˆÙŠØ²ØŒ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ©ØŒ ÙˆØ¨Ù†Ùƒ Ø£Ø³Ø¦Ù„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§**",
        "**Upload your document and get instant AI-powered study materials**"
    ))
    st.markdown("---")

    st.header(T("ğŸ“¤ Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯", "ğŸ“¤ Upload Document"))
    uploaded_file = st.file_uploader(
        T("Ø§Ø®ØªØ± Ù…Ù„Ù (PDF, Word, PowerPoint, Image, TXT)", "Choose a file (PDF, Word, PowerPoint, Image, TXT)"),
        type=["pdf", "docx", "doc", "pptx", "ppt", "txt", "png", "jpg", "jpeg"],
        help=T("Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…: 50 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª", "Maximum file size: 50 MB")
    )

    if uploaded_file:
        is_valid, validation_msg = validate_file(uploaded_file)
        if not is_valid:
            st.error(validation_msg)
            st.stop()
        st.success(validation_msg)

        # Get file content and hash
        file_content = uploaded_file.read()
        uploaded_file.seek(0)
        current_hash = cache.get_file_hash(file_content)
        filename = uploaded_file.name
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù„Ù… ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ù…Ù† Ù‚Ø¨Ù„
        is_new_file = current_hash not in st.session_state['processed_files']

        if is_new_file:
            # Reset features_generated flag for new file
            st.session_state['features_generated'] = False
            
            with st.spinner(T("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯...", "ğŸ”„ Processing document...")):
                ext = get_file_extension(filename)

                if ext == ".docx":
                    extracted_text, metadata = extract_from_word(uploaded_file)
                elif ext == ".txt":
                    extracted_text, metadata = extract_from_txt(uploaded_file)
                elif ext == ".pptx":
                    extracted_text, metadata = pptx_extract_text(uploaded_file, client)
                elif ext in [".pdf", ".png", ".jpg", ".jpeg"]:
                    extracted_text, metadata = ocr_mistral(uploaded_file, filename, client)
                else:
                    st.error(T("âŒ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…", "âŒ Unsupported file type"))
                    st.stop()

                if extracted_text.startswith("Error") or extracted_text.startswith("âŒ"):
                    st.error(extracted_text)
                    st.stop()

                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ÙˆØ§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§
                st.session_state['extracted_text'] = extracted_text
                st.session_state['metadata'] = metadata
                st.session_state['filename'] = filename
                st.session_state['text_hash'] = get_text_hash(extracted_text)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙƒÙ€ "ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡"
                st.session_state['processed_files'][current_hash] = {
                    'filename': filename,
                    'extracted_text': extracted_text,
                    'metadata': metadata,
                    'text_hash': st.session_state['text_hash']
                }

                st.success(T("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!", "âœ… Text extracted successfully!"))

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(T("ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", "ğŸ“ Words"), f"{len(extracted_text.split()):,}")
                with col2:
                    st.metric(T("ğŸ”¤ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ", "ğŸ”¤ Characters"), f"{len(extracted_text):,}")
                with col3:
                    chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)
                    st.metric(T("ğŸ“¦ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡", "ğŸ“¦ Chunks"), len(chunks))

                with st.expander(T("ğŸ‘€ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬", "ğŸ‘€ View Extracted Text")):
                    st.text_area(
                        T("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„", "Full Text"),
                        extracted_text,
                        height=300,
                        key="extracted_text_display"
                    )

                if PDF_AVAILABLE:
                    try:
                        pdf_buffer = create_pdf_from_text(
                            extracted_text,
                            T(f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ - {filename}", f"Extracted Text - {filename}")
                        )
                        st.download_button(
                            label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (PDF)", "ğŸ“¥ Download Extracted Text (PDF)"),
                            data=pdf_buffer,
                            file_name=f"{filename}_extracted.pdf",
                            mime="application/pdf",
                            key="download_extracted_pdf"
                        )
                    except Exception as e:
                        st.warning(f"âš ï¸ PDF Error: {str(e)[:50]}")
                        st.download_button(
                            label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (TXT)", "ğŸ“¥ Download Extracted Text (TXT)"),
                            data=extracted_text,
                            file_name=f"{filename}_extracted.txt",
                            mime="text/plain",
                            key="download_extracted_txt"
                        )
                else:
                    st.download_button(
                        label=T("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (TXT)", "ğŸ“¥ Download Extracted Text (TXT)"),
                        data=extracted_text,
                        file_name=f"{filename}_extracted.txt",
                        mime="text/plain",
                        key="download_extracted_txt"
                    )

                st.markdown("---")

                # Generate features only for new files
                st.header(T("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©...", "ğŸ¤– Generating AI Features..."))
                st.info(T(
                    "Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ù†ØªØ¸Ø± Ù„Ø­Ø¸Ø§Øª Ø­ØªÙ‰ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ.",
                    "Please wait while we generate Arabic and English study materials..."
                ))
                _ = generate_all_features(client, extracted_text, filename)
                st.success(T("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©!", "âœ… Arabic & English versions generated!"))
                
                # Set default selected feature
                st.session_state['selected_feature'] = 'summarize'
                
        else:
            # Ù†ÙØ³ Ø§Ù„Ù…Ù„Ù - Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©
            st.success(T("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!", "âœ… Text extracted successfully!"))
            
            # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            file_data = st.session_state['processed_files'][current_hash]
            st.session_state['extracted_text'] = file_data['extracted_text']
            st.session_state['metadata'] = file_data['metadata']
            st.session_state['filename'] = file_data['filename']
            st.session_state['text_hash'] = file_data['text_hash']
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† features_generated = True
            st.session_state['features_generated'] = True
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(T("ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", "ğŸ“ Words"), f"{len(st.session_state['extracted_text'].split()):,}")
            with col2:
                st.metric(T("ğŸ”¤ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ", "ğŸ”¤ Characters"), f"{len(st.session_state['extracted_text']):,}")
            with col3:
                chunks = chunk_text(st.session_state['extracted_text'], chunk_size, chunk_overlap)
                st.metric(T("ğŸ“¦ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡", "ğŸ“¦ Chunks"), len(chunks))

            with st.expander(T("ğŸ‘€ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬", "ğŸ‘€ View Extracted Text")):
                st.text_area(
                    T("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„", "Full Text"),
                    st.session_state['extracted_text'],
                    height=300,
                    key="extracted_text_display"
                )

    if 'extracted_text' in st.session_state and st.session_state['features_generated']:
        filename = st.session_state['filename']
        ui_lang = st.session_state.get('ui_lang', 'ar')

        st.header(T("ğŸ¯ Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©", "ğŸ¯ Study Features"))
        st.markdown(T(
            "... **Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø£ÙŠ Ø²Ø± Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Ø§ØªØ¬:**",
            "... **Click any button to view the generated content:**"
        ))

        # Ø£Ø²Ø±Ø§Ø± Ù…ØªØ³Ø§ÙˆÙŠØ© Ø§Ù„Ø­Ø¬Ù… (5 Ø£Ø²Ø±Ø§Ø± ÙÙŠ ØµÙ ÙˆØ§Ø­Ø¯)
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            btn_style = "primary" if st.session_state.get('selected_feature') == 'summarize' else "secondary"
            if st.button(T("ğŸ“„ Ø§Ù„Ù…Ù„Ø®Øµ", "ğŸ“„ Summary"), key="btn_summary", use_container_width=True, type=btn_style):
                st.session_state['selected_feature'] = 'summarize'
                st.rerun()
        
        with col2:
            btn_style = "primary" if st.session_state.get('selected_feature') == 'quiz' else "secondary"
            if st.button(T("â“ Ø§Ù„ÙƒÙˆÙŠØ²", "â“ Quiz"), key="btn_quiz", use_container_width=True, type=btn_style):
                st.session_state['selected_feature'] = 'quiz'
                st.rerun()
        
        with col3:
            btn_style = "primary" if st.session_state.get('selected_feature') == 'mindmap' else "secondary"
            if st.button(T("ğŸ§  Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©", "ğŸ§  Mind Map"), key="btn_mindmap", use_container_width=True, type=btn_style):
                st.session_state['selected_feature'] = 'mindmap'
                st.rerun()
        
        with col4:
            btn_style = "primary" if st.session_state.get('selected_feature') == 'questionbank' else "secondary"
            if st.button(T("ğŸ“š Ø¨Ù†Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "ğŸ“š Question Bank"), key="btn_qbank", use_container_width=True, type=btn_style):
                st.session_state['selected_feature'] = 'questionbank'
                st.rerun()
        
        with col5:
            btn_style = "primary" if st.session_state.get('selected_feature') == 'chatbot' else "secondary"
            if st.button(T("ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", "ğŸ’¬ Chat"), key="btn_chat", use_container_width=True, type=btn_style):
                st.session_state['selected_feature'] = 'chatbot'
                st.rerun()

        st.markdown("---")

        features_en = st.session_state.get('features_en', {})
        features_ar = st.session_state.get('features_ar', {})
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ø³Ø®Ø© Ø­Ø³Ø¨ Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
        features = features_ar if ui_lang == 'ar' else features_en

        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ø²Ø± Ø§Ù„Ù…Ø®ØªØ§Ø±
        if st.session_state['selected_feature'] == 'summarize':
            st.subheader(T("ğŸ“„ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø°ÙƒÙŠ", "ğŸ“„ Smart Summary"))
            summary_text = features.get('summary', '')
            if not summary_text:
                st.error(T("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ Ù…ØªØ§Ø­", "âŒ Summary not available"))
            else:
                render_content(summary_text)
                st.markdown("---")
                st.markdown(T("### ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ", "### ğŸ“¥ Download Summary"))
                create_download_button_pdf(
                    summary_text,
                    f"{filename}_summary_{ui_lang}",
                    T("Ø§Ù„Ù…Ù„Ø®Øµ", "Summary"),
                    "download_summary"
                )

        elif st.session_state['selected_feature'] == 'quiz':
            quiz_data = features.get('quiz', {})
            if not quiz_data or not quiz_data.get('questions'):
                st.error(T("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙƒÙˆÙŠØ² Ù…ØªØ§Ø­", "âŒ Quiz not available"))
            else:
                display_interactive_quiz(quiz_data, filename + "_" + ui_lang)

        elif st.session_state['selected_feature'] == 'mindmap':
            st.subheader(T("ğŸ§  Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©", "ğŸ§  Mind Map"))
            mindmap_text = features.get('mindmap', '')
            if not mindmap_text:
                st.error(T("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ù…ØªØ§Ø­Ø©", "âŒ Mind Map not available"))
            else:
                render_content(mindmap_text)
                st.markdown("---")
                st.markdown(T("### ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©", "### ğŸ“¥ Download Mind Map"))
                create_download_button_pdf(
                    mindmap_text,
                    f"{filename}_mindmap_{ui_lang}",
                    T("Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©", "Mind Map"),
                    "download_mindmap"
                )

        elif st.session_state['selected_feature'] == 'questionbank':
            st.subheader(T("ğŸ“š Ø¨Ù†Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "ğŸ“š Question Bank"))
            qb_text = features.get('questionbank', '')
            if not qb_text:
                st.error(T("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨Ù†Ùƒ Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø­", "âŒ Question Bank not available"))
            else:
                render_content(qb_text)
                st.markdown("---")
                st.markdown(T("### ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "### ğŸ“¥ Download Question Bank"))
                create_download_button_pdf(
                    qb_text,
                    f"{filename}_questionbank_{ui_lang}",
                    T("Ø¨Ù†Ùƒ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "Question Bank"),
                    "download_questionbank"
                )

        elif st.session_state['selected_feature'] == 'chatbot':
            display_chat_interface(client, filename)

if __name__ == "__main__":
    main()